{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2 - Decision Tree Practice\n",
    "\n",
    "#### 檔案說明：\n",
    "- hw2.ipynb: 作業主要檔案，讀入資料跑 decision tree ，生出 tree 的 pdf 檔\n",
    "- generate.py: 生測試資料(test.csv)的 script ，用比較不接近訓練資料各欄位數值的比例生成測試資料，並讓 label 符合規則\n",
    "- generate-like.py: 生測試資料(test-like.csv)的 script ，可以用接近訓練資料各欄位數值的比例生成測試資料，並讓 label 符合規則\n",
    "- train.csv: 生出來的 training data (1000筆) (`attendance`還沒標示正確，暫時設定全部為0)\n",
    "- test.csv: 生出來的 test data (1000筆)（`attendance`已經標示正確, 各欄位數值的比例較不接近測試資料）\n",
    "- test-like.csv: 生出來的 test data (1000筆)（`attendance`已經標示正確, 各欄位數值的比例較接近測試資料）\n",
    "- tree.pdf: 跑 hw2.ipynb 生出來的 decision tree 的決策圖 pdf 檔\n",
    "- rule.jpg: 自己設計的分類規則圖\n",
    "\n",
    "## Step 1 - Generate data\n",
    "#### 生成資料: 報名通識講座的1000人是否到場\n",
    "#### 資料欄位解釋（1人1筆資料）: \n",
    "- isStudent: 是否為校內學生（是學生為1, 否則為0）\n",
    "- mayNotGraduate: 畢業危機程度（1至5, 數字越大表示越需要聽通識講座）\n",
    "- interested: 對講座有興趣的程度（1至5, 數字越大表示越有興趣）\n",
    "- alone: 是否一個人參加（一個人參加為1, 結伴參加則為0）\n",
    "- signUpOnline: 是否線上報名（線上報名為1, 當場報名為0）\n",
    "- attendance: 是否出席講座（是則為1, 否則為0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "   isStudent  mayNotGraduate  interested  alone  signUpOnline  attendance\n",
      "0          1               5           5      1             1           0\n",
      "1          1               5           5      1             1           0\n",
      "2          1               5           5      1             1           0\n",
      "3          1               5           5      1             1           0\n",
      "4          1               5           5      1             1           0\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataPathTrain = './train.csv'\n",
    "dataPathTest = './test.csv'\n",
    "dataPathTestLike = './test-like.csv'\n",
    "\n",
    "df = pd.read_csv(dataPathTrain)\n",
    "testDf = pd.read_csv(dataPathTest)\n",
    "testLikeDf = pd.read_csv(dataPathTestLike)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Design rules\n",
    "### 規則樹狀圖\n",
    "（`rule.jpg`）\n",
    "根據規則生出training data 的 label (`attendance`)\n",
    "![rule](rule.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attendance:\n",
      "1: 920 people\n",
      "0: 80 people\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "attendanceList = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if(row['isStudent'] == 1):\n",
    "        if(row['mayNotGraduate'] == 5):\n",
    "            attendanceList.append(1)\n",
    "        else:\n",
    "            if(row['interested'] >= 4):\n",
    "                attendanceList.append(1)\n",
    "            else:\n",
    "                if(row['alone'] == 0):\n",
    "                    attendanceList.append(1)\n",
    "                else:\n",
    "                    if(row['signUpOnline'] == 0):\n",
    "                        attendanceList.append(1)\n",
    "                    else:\n",
    "                        attendanceList.append(0)\n",
    "    else:\n",
    "        if(row['signUpOnline'] == 0):\n",
    "            attendanceList.append(1)\n",
    "        else:\n",
    "            if(row['interested'] >= 3):\n",
    "                if(row['alone'] == 0):\n",
    "                    attendanceList.append(1)\n",
    "                else:\n",
    "                    attendanceList.append(0)\n",
    "            else:\n",
    "                if(row['alone'] == 0):\n",
    "                    attendanceList.append(0)\n",
    "                else:\n",
    "                    attendanceList.append(1)\n",
    "\n",
    "counter = Counter(attendanceList)\n",
    "print('attendance:')\n",
    "for key in counter:\n",
    "    print('%d: %d people' % (key, counter[key]))\n",
    "\n",
    "attendanceDf = pd.DataFrame({'attendance': attendanceList})\n",
    "df.update(attendanceDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Build a decision tree\n",
    "分離x（各個feature）, y(attendance) 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data x:\n",
      "   isStudent  mayNotGraduate  interested  alone  signUpOnline\n",
      "0          1               5           5      1             1\n",
      "1          1               5           5      1             1\n",
      "2          1               5           5      1             1\n",
      "3          1               5           5      1             1\n",
      "4          1               5           5      1             1\n",
      "\n",
      "data y:\n",
      "   attendance\n",
      "0           1\n",
      "1           1\n",
      "2           1\n",
      "3           1\n",
      "4           1\n",
      "\n",
      "accuracy:\n",
      "0.978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataX = df[['isStudent', 'mayNotGraduate', 'interested', 'alone', 'signUpOnline']]\n",
    "dataY = df[['attendance']]\n",
    "\n",
    "testX = testDf[['isStudent', 'mayNotGraduate', 'interested', 'alone', 'signUpOnline']]\n",
    "testY = testDf[['attendance']]\n",
    "\n",
    "print('data x:')\n",
    "print(dataX.head())\n",
    "print('\\ndata y:')\n",
    "print(dataY.head())\n",
    "\n",
    "mTree = DecisionTreeClassifier()\n",
    "\n",
    "mTree.fit(dataX, dataY)\n",
    "predictY = mTree.predict(testX)\n",
    "\n",
    "print('\\naccuracy:')\n",
    "print(accuracy_score(testY, predictY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Plot the decision tree\n",
    "產生一個 decision tree 的決策圖(`tree.pdf`)在同一層資料夾中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iris/.local/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO   \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "treeDataPath = './tree.pdf'\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(mTree, \n",
    "                out_file=dot_data,  \n",
    "                filled=True, \n",
    "                feature_names=list(dataX),\n",
    "                class_names=['absent', 'present'],\n",
    "                special_characters=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_pdf(treeDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Discussion\n",
    "scikit-learn 的 decision tree 預設參數可以讓它完全 fit 訓練資料，所以最後訓練出來的 decision tree 決策圖中，每筆不同的資料都可能各有一個 node。加了其它參數之後，反而會讓 decision tree 往較不會過於 fit 訓練資料的方向調整(例如min_samples_split, max_depth, max_features, max_leaf_nodes等)，因此在這次作業的情況(資料都可以完全依照清楚的規則被區分不同label)中，調整參數過後的 decision tree 跑測試資料時的 accuracy 都比沒調過參數的 decision tree 還要低。\n",
    "\n",
    "沒調過參數的 decision tree 做出的決策圖，從`tree.pdf`的 leaf node 中 value 都有一邊是 0 就可以看出這個 decision tree 已經自己找到一個可以完全把訓練資料的 label 分得完全無誤的規則了。\n",
    "\n",
    "scikit-learn 的 decision tree 預設 criterion 為 gini，因此 decision tree 會先將 gini 值最接近 0 (最容易區分不同 label)的欄位 `alone` 作為 decision tree 的 root。當初訂定規則時，的確也有因為覺得如果是結伴報名(`alone`=0)那就表示可能跟朋友約好了所以不會臨時報名了卻沒到，後來把`alone`放在規則判斷比較後面的部份。下面印出按照原本的規則去分 label 時，最後是被`alone`這個欄位確認label的資料數，以及被其它欄位確認label的資料數，可以看到最後是被`alone`這個欄位確認label的資料數最多，所以`alone`這個欄位比較能夠正確的區分不同label的資料，因此被 decision tree 放在 root 是合理的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305\n",
      "146\n",
      "403\n",
      "20\n",
      "76\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "dataNumSplitByAlone = 0\n",
    "dataNum1 = 0\n",
    "dataNum2 = 0\n",
    "dataNum3 = 0\n",
    "dataNum4 = 0\n",
    "dataNum5 = 0\n",
    "testAttendanceList = []\n",
    "for index, row in testDf.iterrows():\n",
    "    if(row['isStudent'] == 1):\n",
    "        if(row['mayNotGraduate'] == 5):\n",
    "            testAttendanceList.append(1)\n",
    "            dataNum1 += 1\n",
    "        else:\n",
    "            if(row['interested'] >= 4):\n",
    "                testAttendanceList.append(1)\n",
    "                dataNum2 += 1\n",
    "            else:\n",
    "                if(row['alone'] == 0):\n",
    "                    testAttendanceList.append(1)\n",
    "                    dataNumSplitByAlone += 1\n",
    "                else:\n",
    "                    if(row['signUpOnline'] == 0):\n",
    "                        testAttendanceList.append(1)\n",
    "                        dataNum3 += 1\n",
    "                    else:\n",
    "                        testAttendanceList.append(0)\n",
    "                        dataNum4 += 1\n",
    "    else:\n",
    "        if(row['signUpOnline'] == 0):\n",
    "            testAttendanceList.append(1)\n",
    "            dataNum5 += 1\n",
    "        else:\n",
    "            dataNumSplitByAlone += 1\n",
    "            if(row['interested'] >= 3):\n",
    "                if(row['alone'] == 0):\n",
    "                    testAttendanceList.append(1)\n",
    "                else:\n",
    "                    testAttendanceList.append(0)\n",
    "            else:\n",
    "                if(row['alone'] == 0):\n",
    "                    testAttendanceList.append(0)\n",
    "                else:\n",
    "                    testAttendanceList.append(1)\n",
    "                    \n",
    "print(dataNumSplitByAlone)\n",
    "print(dataNum1)\n",
    "print(dataNum2)\n",
    "print(dataNum3)\n",
    "print(dataNum4)\n",
    "print(dataNum5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面用原本各欄位的每個數值比例比較接近原本訓練資料的測試資料再跑一次同樣的 decision tree 就發現 accuracy 變高了，推測應該是因為數值比例接近的測試資料跟訓練資料應該會比較像。\n",
    "實際再把重複的資料刪除之後發現 accuracy 比較低 (0.978) 的測試資料比訓練資料多出一倍的不同資料，所以accuracy比跟訓練資料相近的測試資料低也是較為合理的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy:\n",
      "0.998\n"
     ]
    }
   ],
   "source": [
    "testLikeX = testLikeDf[['isStudent', 'mayNotGraduate', 'interested', 'alone', 'signUpOnline']]\n",
    "testLikeY = testLikeDf[['attendance']]\n",
    "\n",
    "predictLikeY = mTree.predict(testLikeX)\n",
    "\n",
    "print('\\naccuracy:')\n",
    "print(accuracy_score(testLikeY, predictLikeY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n",
      "(75, 6)\n",
      "\n",
      "test data\n",
      "(147, 6)\n",
      "\n",
      "test data which are more like the training data\n",
      "(96, 6)\n"
     ]
    }
   ],
   "source": [
    "print('training data')\n",
    "print(df.drop_duplicates().shape)\n",
    "print('\\ntest data')\n",
    "print(testDf.drop_duplicates().shape)\n",
    "print('\\ntest data which are more like the training data')\n",
    "print(testLikeDf.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將 test-like.csv 測試資料中分類錯誤的資料印出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isStudent         0\n",
      "mayNotGraduate    1\n",
      "interested        2\n",
      "alone             1\n",
      "signUpOnline      1\n",
      "attendance        1\n",
      "Name: 260, dtype: int64\n",
      "isStudent         0\n",
      "mayNotGraduate    1\n",
      "interested        1\n",
      "alone             0\n",
      "signUpOnline      0\n",
      "attendance        1\n",
      "Name: 927, dtype: int64\n",
      "\n",
      "number of wrong prediction:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "count = 0\n",
    "for index, row in testLikeDf.iterrows():\n",
    "    if(row['attendance'] != predictLikeY[i]):\n",
    "        print(row)\n",
    "        count += 1\n",
    "    i += 1\n",
    "print('\\nnumber of wrong prediction:')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把 decision tree 的決策圖寫成 if-else 規則，實際去跑一次測試資料，發現錯誤分類最多次的node跟決策圖上 gini 值最接近 0.5 （比較沒辦法正確分開不同 label 的 attribute）的node是一樣的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "17\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "---\n",
      "20\n",
      "102\n",
      "21\n",
      "---\n",
      "0.15\n",
      "0.16666666666666666\n",
      "0.09523809523809523\n"
     ]
    }
   ],
   "source": [
    "wrong1 = 0\n",
    "wrong2 = 0\n",
    "wrong3 = 0\n",
    "wrong4 = 0\n",
    "wrong5 = 0\n",
    "wrong6 = 0\n",
    "wrong7 = 0\n",
    "wrong8 = 0\n",
    "wrong9 = 0\n",
    "num1 = 0\n",
    "num5 = 0\n",
    "num6 = 0\n",
    "for index, row in testDf.iterrows():\n",
    "    if(row['alone']<=0.5):\n",
    "        if(row['isStudent']<=0.5):\n",
    "            if(row['interested']<=2.5):\n",
    "                num1 += 1\n",
    "                if(row['attendance']!=0):\n",
    "                    wrong1 += 1\n",
    "            else:\n",
    "                if(row['attendance']!=1):\n",
    "                    wrong2 += 1\n",
    "        else:\n",
    "            if(row['attendance']!=1):\n",
    "                wrong3 += 1\n",
    "    else:\n",
    "        if(row['interested']<=3.5):\n",
    "            if(row['mayNotGraduate'] <= 4.5):\n",
    "                if(row['signUpOnline']<=0.5):\n",
    "                    if(row['attendance']!=1):\n",
    "                        wrong4 += 1\n",
    "                else:\n",
    "                    num5+=1\n",
    "                    if(row['attendance']!=0):\n",
    "                        wrong5 += 1\n",
    "            else:\n",
    "                num6 += 1\n",
    "                if(row['attendance']!=1):\n",
    "                    wrong6 += 1\n",
    "        else:\n",
    "            if(row['isStudent']<=0.5):\n",
    "                if(row['signUpOnline']<=0.5):\n",
    "                    if(row['attendance']!=1):\n",
    "                        wrong7 += 1\n",
    "                else:\n",
    "                    if(row['attendance']!=0):\n",
    "                        wrong8 += 1\n",
    "            else:\n",
    "                if(row['attendance']!=1):\n",
    "                        wrong9 += 1\n",
    "\n",
    "print(wrong1)\n",
    "print(wrong2)\n",
    "print(wrong3)\n",
    "print(wrong4)\n",
    "print(wrong5)\n",
    "print(wrong6)\n",
    "print(wrong7)\n",
    "print(wrong8)\n",
    "print(wrong9)\n",
    "print('---')\n",
    "print(num1)\n",
    "print(num5)\n",
    "print(num6)\n",
    "print('---')\n",
    "print(wrong1/num1)\n",
    "print(wrong5/num5)\n",
    "print(wrong6/num6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Other Classifiers\n",
    "下面利用 grid search 試著找出適合的分類器參數，以下用的三種分類器分別為: Random forest classifer, Ada boost classifer 以及 Support vector classifier。將訓練資料分為 5 個 fold 去測試各種參數組合的 accuracy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== Random Forest Classifier ===============\n",
      "0.801 (+/-0.292) for {'max_depth': 3, 'max_leaf_nodes': 5, 'n_estimators': 20}\n",
      "0.720 (+/-0.554) for {'max_depth': 3, 'max_leaf_nodes': 5, 'n_estimators': 50}\n",
      "0.806 (+/-0.309) for {'max_depth': 3, 'max_leaf_nodes': 5, 'n_estimators': 100}\n",
      "0.760 (+/-0.414) for {'max_depth': 3, 'max_leaf_nodes': 5, 'n_estimators': 200}\n",
      "0.771 (+/-0.412) for {'max_depth': 3, 'max_leaf_nodes': 5, 'n_estimators': 300}\n",
      "0.813 (+/-0.572) for {'max_depth': 3, 'max_leaf_nodes': 10, 'n_estimators': 20}\n",
      "0.929 (+/-0.084) for {'max_depth': 3, 'max_leaf_nodes': 10, 'n_estimators': 50}\n",
      "0.720 (+/-0.554) for {'max_depth': 3, 'max_leaf_nodes': 10, 'n_estimators': 100}\n",
      "0.720 (+/-0.554) for {'max_depth': 3, 'max_leaf_nodes': 10, 'n_estimators': 200}\n",
      "0.764 (+/-0.401) for {'max_depth': 3, 'max_leaf_nodes': 10, 'n_estimators': 300}\n",
      "0.729 (+/-0.568) for {'max_depth': 3, 'max_leaf_nodes': 30, 'n_estimators': 20}\n",
      "0.720 (+/-0.554) for {'max_depth': 3, 'max_leaf_nodes': 30, 'n_estimators': 50}\n",
      "0.749 (+/-0.451) for {'max_depth': 3, 'max_leaf_nodes': 30, 'n_estimators': 100}\n",
      "0.720 (+/-0.554) for {'max_depth': 3, 'max_leaf_nodes': 30, 'n_estimators': 200}\n",
      "0.719 (+/-0.555) for {'max_depth': 3, 'max_leaf_nodes': 30, 'n_estimators': 300}\n",
      "0.839 (+/-0.421) for {'max_depth': 3, 'max_leaf_nodes': 50, 'n_estimators': 20}\n",
      "0.768 (+/-0.429) for {'max_depth': 3, 'max_leaf_nodes': 50, 'n_estimators': 50}\n",
      "0.723 (+/-0.543) for {'max_depth': 3, 'max_leaf_nodes': 50, 'n_estimators': 100}\n",
      "0.798 (+/-0.299) for {'max_depth': 3, 'max_leaf_nodes': 50, 'n_estimators': 200}\n",
      "0.720 (+/-0.554) for {'max_depth': 3, 'max_leaf_nodes': 50, 'n_estimators': 300}\n",
      "0.875 (+/-0.244) for {'max_depth': 5, 'max_leaf_nodes': 5, 'n_estimators': 20}\n",
      "0.711 (+/-0.634) for {'max_depth': 5, 'max_leaf_nodes': 5, 'n_estimators': 50}\n",
      "0.788 (+/-0.664) for {'max_depth': 5, 'max_leaf_nodes': 5, 'n_estimators': 100}\n",
      "0.744 (+/-0.576) for {'max_depth': 5, 'max_leaf_nodes': 5, 'n_estimators': 200}\n",
      "0.744 (+/-0.590) for {'max_depth': 5, 'max_leaf_nodes': 5, 'n_estimators': 300}\n",
      "0.750 (+/-0.689) for {'max_depth': 5, 'max_leaf_nodes': 10, 'n_estimators': 20}\n",
      "0.750 (+/-0.689) for {'max_depth': 5, 'max_leaf_nodes': 10, 'n_estimators': 50}\n",
      "0.849 (+/-0.370) for {'max_depth': 5, 'max_leaf_nodes': 10, 'n_estimators': 100}\n",
      "0.777 (+/-0.593) for {'max_depth': 5, 'max_leaf_nodes': 10, 'n_estimators': 200}\n",
      "0.771 (+/-0.614) for {'max_depth': 5, 'max_leaf_nodes': 10, 'n_estimators': 300}\n",
      "0.771 (+/-0.620) for {'max_depth': 5, 'max_leaf_nodes': 30, 'n_estimators': 20}\n",
      "0.847 (+/-0.587) for {'max_depth': 5, 'max_leaf_nodes': 30, 'n_estimators': 50}\n",
      "0.895 (+/-0.300) for {'max_depth': 5, 'max_leaf_nodes': 30, 'n_estimators': 100}\n",
      "0.768 (+/-0.625) for {'max_depth': 5, 'max_leaf_nodes': 30, 'n_estimators': 200}\n",
      "0.897 (+/-0.293) for {'max_depth': 5, 'max_leaf_nodes': 30, 'n_estimators': 300}\n",
      "0.750 (+/-0.689) for {'max_depth': 5, 'max_leaf_nodes': 50, 'n_estimators': 20}\n",
      "0.836 (+/-0.447) for {'max_depth': 5, 'max_leaf_nodes': 50, 'n_estimators': 50}\n",
      "0.812 (+/-0.476) for {'max_depth': 5, 'max_leaf_nodes': 50, 'n_estimators': 100}\n",
      "0.767 (+/-0.626) for {'max_depth': 5, 'max_leaf_nodes': 50, 'n_estimators': 200}\n",
      "0.767 (+/-0.626) for {'max_depth': 5, 'max_leaf_nodes': 50, 'n_estimators': 300}\n",
      "0.863 (+/-0.444) for {'max_depth': 8, 'max_leaf_nodes': 5, 'n_estimators': 20}\n",
      "0.782 (+/-0.445) for {'max_depth': 8, 'max_leaf_nodes': 5, 'n_estimators': 50}\n",
      "0.780 (+/-0.448) for {'max_depth': 8, 'max_leaf_nodes': 5, 'n_estimators': 100}\n",
      "0.826 (+/-0.319) for {'max_depth': 8, 'max_leaf_nodes': 5, 'n_estimators': 200}\n",
      "0.817 (+/-0.589) for {'max_depth': 8, 'max_leaf_nodes': 5, 'n_estimators': 300}\n",
      "0.809 (+/-0.485) for {'max_depth': 8, 'max_leaf_nodes': 10, 'n_estimators': 20}\n",
      "0.806 (+/-0.481) for {'max_depth': 8, 'max_leaf_nodes': 10, 'n_estimators': 50}\n",
      "0.855 (+/-0.358) for {'max_depth': 8, 'max_leaf_nodes': 10, 'n_estimators': 100}\n",
      "0.897 (+/-0.293) for {'max_depth': 8, 'max_leaf_nodes': 10, 'n_estimators': 200}\n",
      "0.809 (+/-0.485) for {'max_depth': 8, 'max_leaf_nodes': 10, 'n_estimators': 300}\n",
      "0.773 (+/-0.677) for {'max_depth': 8, 'max_leaf_nodes': 30, 'n_estimators': 20}\n",
      "0.815 (+/-0.466) for {'max_depth': 8, 'max_leaf_nodes': 30, 'n_estimators': 50}\n",
      "0.766 (+/-0.627) for {'max_depth': 8, 'max_leaf_nodes': 30, 'n_estimators': 100}\n",
      "0.853 (+/-0.360) for {'max_depth': 8, 'max_leaf_nodes': 30, 'n_estimators': 200}\n",
      "0.768 (+/-0.625) for {'max_depth': 8, 'max_leaf_nodes': 30, 'n_estimators': 300}\n",
      "0.798 (+/-0.476) for {'max_depth': 8, 'max_leaf_nodes': 50, 'n_estimators': 20}\n",
      "0.778 (+/-0.600) for {'max_depth': 8, 'max_leaf_nodes': 50, 'n_estimators': 50}\n",
      "0.771 (+/-0.614) for {'max_depth': 8, 'max_leaf_nodes': 50, 'n_estimators': 100}\n",
      "0.767 (+/-0.626) for {'max_depth': 8, 'max_leaf_nodes': 50, 'n_estimators': 200}\n",
      "0.768 (+/-0.625) for {'max_depth': 8, 'max_leaf_nodes': 50, 'n_estimators': 300}\n",
      "Best parameters set found on development set:{'max_depth': 3, 'max_leaf_nodes': 10, 'n_estimators': 50}\n",
      "\n",
      "testing accuracy:0.904\n",
      "\n",
      "=============== AdaBoost Classifier ===============\n",
      "0.963 (+/-0.107) for {'algorithm': 'SAMME', 'n_estimators': 30}\n",
      "0.971 (+/-0.089) for {'algorithm': 'SAMME', 'n_estimators': 50}\n",
      "0.971 (+/-0.089) for {'algorithm': 'SAMME', 'n_estimators': 100}\n",
      "0.846 (+/-0.586) for {'algorithm': 'SAMME.R', 'n_estimators': 30}\n",
      "0.846 (+/-0.586) for {'algorithm': 'SAMME.R', 'n_estimators': 50}\n",
      "0.885 (+/-0.431) for {'algorithm': 'SAMME.R', 'n_estimators': 100}\n",
      "Best parameters set found on development set:{'algorithm': 'SAMME', 'n_estimators': 50}\n",
      "\n",
      "testing accuracy:0.953\n",
      "\n",
      "=============== Support Vector Classifier ===============\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.805 (+/-0.397) for {'C': 0.01, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.788 (+/-0.462) for {'C': 0.01, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.807 (+/-0.425) for {'C': 0.01, 'coef0': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 10, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.874 (+/-0.345) for {'C': 0.01, 'coef0': 10, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 10, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.968 (+/-0.063) for {'C': 0.01, 'coef0': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 100, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.963 (+/-0.073) for {'C': 0.01, 'coef0': 100, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.981 (+/-0.047) for {'C': 0.01, 'coef0': 100, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.01, 'coef0': 100, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.892 (+/-0.304) for {'C': 0.1, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.824 (+/-0.384) for {'C': 0.1, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.799 (+/-0.372) for {'C': 0.1, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.816 (+/-0.349) for {'C': 0.1, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.824 (+/-0.384) for {'C': 0.1, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.799 (+/-0.372) for {'C': 0.1, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.914 (+/-0.296) for {'C': 0.1, 'coef0': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.824 (+/-0.384) for {'C': 0.1, 'coef0': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.862 (+/-0.291) for {'C': 0.1, 'coef0': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 10, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.939 (+/-0.101) for {'C': 0.1, 'coef0': 10, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.824 (+/-0.384) for {'C': 0.1, 'coef0': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 10, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.974 (+/-0.072) for {'C': 0.1, 'coef0': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 100, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.946 (+/-0.095) for {'C': 0.1, 'coef0': 100, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.824 (+/-0.384) for {'C': 0.1, 'coef0': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.960 (+/-0.075) for {'C': 0.1, 'coef0': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.963 (+/-0.073) for {'C': 0.1, 'coef0': 100, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 0.1, 'coef0': 100, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.976 (+/-0.057) for {'C': 1, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.907 (+/-0.256) for {'C': 1, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 1, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.869 (+/-0.393) for {'C': 1, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.951 (+/-0.133) for {'C': 1, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.806 (+/-0.456) for {'C': 1, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.970 (+/-0.073) for {'C': 1, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.907 (+/-0.256) for {'C': 1, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 1, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.816 (+/-0.349) for {'C': 1, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.951 (+/-0.133) for {'C': 1, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.819 (+/-0.404) for {'C': 1, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.957 (+/-0.085) for {'C': 1, 'coef0': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.907 (+/-0.256) for {'C': 1, 'coef0': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 1, 'coef0': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.905 (+/-0.293) for {'C': 1, 'coef0': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.951 (+/-0.133) for {'C': 1, 'coef0': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 1, 'coef0': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 10, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.939 (+/-0.101) for {'C': 1, 'coef0': 10, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.907 (+/-0.256) for {'C': 1, 'coef0': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 1, 'coef0': 10, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.939 (+/-0.101) for {'C': 1, 'coef0': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.951 (+/-0.133) for {'C': 1, 'coef0': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 1, 'coef0': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 100, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.946 (+/-0.095) for {'C': 1, 'coef0': 100, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.907 (+/-0.256) for {'C': 1, 'coef0': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 1, 'coef0': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.973 (+/-0.056) for {'C': 1, 'coef0': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.963 (+/-0.073) for {'C': 1, 'coef0': 100, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.951 (+/-0.133) for {'C': 1, 'coef0': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 1, 'coef0': 100, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.962 (+/-0.089) for {'C': 10, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 10, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.710 (+/-0.518) for {'C': 10, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.976 (+/-0.057) for {'C': 10, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.941 (+/-0.126) for {'C': 10, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.800 (+/-0.475) for {'C': 10, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.962 (+/-0.089) for {'C': 10, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 10, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.710 (+/-0.518) for {'C': 10, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.963 (+/-0.090) for {'C': 10, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.941 (+/-0.126) for {'C': 10, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.796 (+/-0.491) for {'C': 10, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.957 (+/-0.085) for {'C': 10, 'coef0': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 10, 'coef0': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.886 (+/-0.136) for {'C': 10, 'coef0': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.962 (+/-0.073) for {'C': 10, 'coef0': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.941 (+/-0.126) for {'C': 10, 'coef0': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.797 (+/-0.492) for {'C': 10, 'coef0': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 10, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.939 (+/-0.101) for {'C': 10, 'coef0': 10, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 10, 'coef0': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 10, 'coef0': 10, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.939 (+/-0.101) for {'C': 10, 'coef0': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.941 (+/-0.126) for {'C': 10, 'coef0': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 10, 'coef0': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 100, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.946 (+/-0.095) for {'C': 10, 'coef0': 100, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 10, 'coef0': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 10, 'coef0': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 10, 'coef0': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.963 (+/-0.073) for {'C': 10, 'coef0': 100, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.941 (+/-0.126) for {'C': 10, 'coef0': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 10, 'coef0': 100, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.968 (+/-0.113) for {'C': 100, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 100, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.672 (+/-0.604) for {'C': 100, 'coef0': 0.01, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.962 (+/-0.089) for {'C': 100, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.940 (+/-0.145) for {'C': 100, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.800 (+/-0.475) for {'C': 100, 'coef0': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.975 (+/-0.085) for {'C': 100, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 100, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.672 (+/-0.604) for {'C': 100, 'coef0': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.962 (+/-0.089) for {'C': 100, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.940 (+/-0.145) for {'C': 100, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.796 (+/-0.491) for {'C': 100, 'coef0': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.957 (+/-0.085) for {'C': 100, 'coef0': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 100, 'coef0': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.678 (+/-0.594) for {'C': 100, 'coef0': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.975 (+/-0.069) for {'C': 100, 'coef0': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.940 (+/-0.145) for {'C': 100, 'coef0': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.705 (+/-0.532) for {'C': 100, 'coef0': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 10, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.939 (+/-0.101) for {'C': 100, 'coef0': 10, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 100, 'coef0': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 100, 'coef0': 10, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.939 (+/-0.101) for {'C': 100, 'coef0': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.940 (+/-0.145) for {'C': 100, 'coef0': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 100, 'coef0': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 100, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "0.946 (+/-0.095) for {'C': 100, 'coef0': 100, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.894 (+/-0.376) for {'C': 100, 'coef0': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 100, 'coef0': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.977 (+/-0.042) for {'C': 100, 'coef0': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "0.963 (+/-0.073) for {'C': 100, 'coef0': 100, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.940 (+/-0.145) for {'C': 100, 'coef0': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.920 (+/-0.000) for {'C': 100, 'coef0': 100, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Best parameters set found on development set:{'C': 0.01, 'coef0': 100, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "testing accuracy:0.976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mRFC = RandomForestClassifier()\n",
    "mABC = AdaBoostClassifier()\n",
    "mSVC = SVC()\n",
    "\n",
    "m_classifiers = {\n",
    "    'Random Forest Classifier': {\n",
    "        'clf': mRFC,\n",
    "        'tuned_parameters': [{\n",
    "            'n_estimators': [20, 50, 100, 200, 300],\n",
    "            'max_depth': [3, 5, 8],\n",
    "            'max_leaf_nodes': [5, 10, 30, 50],\n",
    "        }],\n",
    "    },\n",
    "    'AdaBoost Classifier': {\n",
    "        'clf': mABC,\n",
    "        'tuned_parameters': [{\n",
    "            'n_estimators': [30, 50, 100],\n",
    "            'algorithm': ['SAMME', 'SAMME.R'],\n",
    "        }],\n",
    "    },\n",
    "    'Support Vector Classifier': {\n",
    "        'clf': mSVC,\n",
    "        'tuned_parameters': [{\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'coef0': [0.01, 0.1, 1, 10, 100],\n",
    "            'gamma': ['auto', 'scale'],\n",
    "        }],\n",
    "    },\n",
    "}\n",
    "\n",
    "for clf_key in m_classifiers.keys():\n",
    "    print('\\n=============== %s ===============' % (clf_key))\n",
    "    clf = GridSearchCV(\n",
    "        m_classifiers[clf_key]['clf'],\n",
    "        m_classifiers[clf_key]['tuned_parameters'],\n",
    "        cv=5,\n",
    "        scoring='accuracy')\n",
    "    clf.fit(dataX, dataY.values.ravel())\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    \n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "    print(\"Best parameters set found on development set:\", end='')\n",
    "    print(clf.best_params_)\n",
    "        \n",
    "    predictY = clf.predict(testX)\n",
    "    print('\\ntesting accuracy:', end='')\n",
    "    print(accuracy_score(testY, predictY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將上面 grid search 所找到的最佳參數拿去跑測試資料，將測試資料跑出的 accuracy 結果印出。可以看到跑出來的 accuracy 都 >= 原本上面沒調過參數的分類器跑出來的 accuracy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random forest classifier - testing accuracy using best params:0.944\n",
      "\n",
      "AdaBoost classifier - testing accuracy using best params:0.953\n",
      "\n",
      "Support vector classifier - testing accuracy using best params:0.976\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=3, max_leaf_nodes=10, n_estimators=50)\n",
    "clf.fit(dataX, dataY.values.ravel())\n",
    "predictY = clf.predict(testX)\n",
    "print('\\nRandom forest classifier - testing accuracy using best params:', end='')\n",
    "print(accuracy_score(testY, predictY))\n",
    "\n",
    "clf = AdaBoostClassifier(algorithm='SAMME', n_estimators=50)\n",
    "clf.fit(dataX, dataY.values.ravel())\n",
    "predictY = clf.predict(testX)\n",
    "print('\\nAdaBoost classifier - testing accuracy using best params:', end='')\n",
    "print(accuracy_score(testY, predictY))\n",
    "\n",
    "clf = SVC(C=0.01, coef0=100, gamma='scale', kernel='poly')\n",
    "clf.fit(dataX, dataY.values.ravel())\n",
    "predictY = clf.predict(testX)\n",
    "print('\\nSupport vector classifier - testing accuracy using best params:', end='')\n",
    "print(accuracy_score(testY, predictY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 補充\n",
    "- sklearn 版本\n",
    "- 測試 test data 是否 label 正確"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels which are different from the correct labels (generated by the rules):\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check if test data follow the rule\n",
    "\n",
    "testAttendanceList = []\n",
    "for index, row in testDf.iterrows():\n",
    "    if(row['isStudent'] == 1):\n",
    "        if(row['mayNotGraduate'] == 5):\n",
    "            testAttendanceList.append(1)\n",
    "        else:\n",
    "            if(row['interested'] >= 4):\n",
    "                testAttendanceList.append(1)\n",
    "            else:\n",
    "                if(row['alone'] == 0):\n",
    "                    testAttendanceList.append(1)\n",
    "                else:\n",
    "                    if(row['signUpOnline'] == 0):\n",
    "                        testAttendanceList.append(1)\n",
    "                    else:\n",
    "                        testAttendanceList.append(0)\n",
    "    else:\n",
    "        if(row['signUpOnline'] == 0):\n",
    "            testAttendanceList.append(1)\n",
    "        else:\n",
    "            if(row['interested'] >= 3):\n",
    "                if(row['alone'] == 0):\n",
    "                    testAttendanceList.append(1)\n",
    "                else:\n",
    "                    testAttendanceList.append(0)\n",
    "            else:\n",
    "                if(row['alone'] == 0):\n",
    "                    testAttendanceList.append(0)\n",
    "                else:\n",
    "                    testAttendanceList.append(1)\n",
    "                    \n",
    "i=0\n",
    "diff=0\n",
    "for index, row in testDf.iterrows():\n",
    "    if(row['attendance'] != testAttendanceList[i]):\n",
    "        diff += 1\n",
    "    i+=1\n",
    "    \n",
    "print('Number of labels which are different from the correct labels (generated by the rules):')\n",
    "print(diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
